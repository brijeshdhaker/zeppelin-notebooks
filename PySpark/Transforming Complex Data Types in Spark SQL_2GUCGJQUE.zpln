{
  "paragraphs": [
    {
      "text": "%pyspark\n\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\n# Convenience function for turning JSON strings into DataFrames.\ndef jsonToDataFrame(json, schema\u003dNone):\n  # SparkSessions are available with Spark 2.0+\n  reader \u003d spark.read\n  if schema:\n    reader.schema(schema)\n  return reader.json(sc.parallelize([json]))",
      "user": "anonymous",
      "dateUpdated": "2022-01-06 01:17:21.136",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 11.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1641431773904_889075011",
      "id": "paragraph_1641431773904_889075011",
      "dateCreated": "2022-01-06 01:16:13.904",
      "status": "READY"
    },
    {
      "text": "%md\n\nSelecting from nested columns - Dots (\".\") can be used to access nested columns for structs and maps.\n",
      "user": "anonymous",
      "dateUpdated": "2022-01-06 01:20:06.027",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 11.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1641431865282_695059360",
      "id": "paragraph_1641431865282_695059360",
      "dateCreated": "2022-01-06 01:17:45.282",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# Using a struct\nschema \u003d StructType().add(\"a\", StructType().add(\"b\", IntegerType()))\n                          \nevents \u003d jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n     \"b\": 1\n  }\n}\n\"\"\", schema)\n\ndisplay(events.select(\"a.b\"))",
      "user": "anonymous",
      "dateUpdated": "2022-01-06 01:21:23.921",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 11.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1641431841293_1052578850",
      "id": "paragraph_1641431841293_1052578850",
      "dateCreated": "2022-01-06 01:17:21.293",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# Using a map\nschema \u003d StructType().add(\"a\", MapType(StringType(), IntegerType()))\n                          \nevents \u003d jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n     \"b\": 1\n  }\n}\n\"\"\", schema)\n\ndisplay(events.select(\"a.b\"))\n",
      "user": "anonymous",
      "dateUpdated": "2022-01-06 01:21:29.643",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 11.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1641431904944_1632955842",
      "id": "paragraph_1641431904944_1632955842",
      "dateCreated": "2022-01-06 01:18:24.944",
      "status": "READY"
    }
  ],
  "name": "Transforming Complex Data Types in Spark SQL",
  "id": "2GUCGJQUE",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}